# Fine-tuning

See also:
- https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e#training-your-own
- "Why You (Probably) Don't Need to Fine-tune an LLM" (instead, use few-shot prompting & retrieval-augmented generation) https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm

Overview/summary table:

Name | HW Requirements | Evaluation | Licence | Inference
--|--|--|--|--
**Text**|
Gorilla |
Falcon |
**Images** |
... |
**Audio** |
... |
**Code** |
... |

## How Fine-tuning Works

## links to maybe mention

- "Fine-Tuning Llama-2: A Comprehensive Case Study for Tailoring Models to Unique Applications" (fine-tuning LLaMA-2 for 3 real-world use cases) https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications
- "Private, local, open source LLMs" https://python.langchain.com/docs/guides/local_llms

  ```{figure-md}
  ![](https://python.langchain.com/assets/images/OSS_LLM_overview-b0a96cc35216ec43c3ccde7ed1140854.png)

  [Open Source LLMs](https://python.langchain.com/docs/guides/local_llms)
  ```

- "Easy-to-use LLM fine-tuning framework (LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, ChatGLM2)" https://github.com/hiyouga/LLaMA-Efficient-Tuning
- https://dstack.ai/examples/finetuning-llama-2
- https://github.com/h2oai, etc.
- "The History of Open-Source LLMs: Better Base Models (part 2)" (LLaMA, MPT, Falcon, LLaMA-2) https://cameronrwolfe.substack.com/p/the-history-of-open-source-llms-better

## LLMs

### Gorilla

### Falcon

## Image Models

### Stable Diffusion

## Audio

### Whisper Tiny

### Bark

## Code Generators

{{ comments }}
